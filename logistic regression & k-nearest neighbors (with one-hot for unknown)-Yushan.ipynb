{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files into dataframe and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Root_Insurance_Data.csv'\n",
    "root = pd.read_csv(file)\n",
    "root_copy = root.copy()\n",
    "X = root_copy[['Currently Insured','Number of Vehicles','Number of Drivers','Marital Status','rank']]\n",
    "y = root_copy[['click','policies_sold']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 614, \n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using one-hot converting 'insured or not' and 'marital status' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = X_train.loc[:,['Currently Insured','Number of Vehicles','Number of Drivers','Marital Status','rank']].copy()\n",
    "X1_train['Married'] = pd.get_dummies(X1_train.loc[:,'Marital Status'])['M']\n",
    "X1_train['Insured'] = pd.get_dummies(X1_train.loc[:,'Currently Insured'])['Y']\n",
    "X1_train['NotInsured'] = pd.get_dummies(X1_train.loc[:,'Currently Insured'])['N']\n",
    "X1_train = X1_train.loc[:,['Number of Vehicles','rank','Insured','NotInsured','Number of Drivers','Married']]\n",
    "click_train = y_train.loc[:,'click'].copy()\n",
    "policy_train = y_train.loc[:,'policies_sold'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression for clicking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X1_train,click_train)\n",
    "\"\"\"\n",
    "The code below is for checking the accuracy,precision and recall:\n",
    "\n",
    "click_prob = log_reg.predict_proba(X1_train)[:,1]\n",
    "cutoffs = np.arange(0,1.01,.01)\n",
    "accs = []\n",
    "for cutoff in cutoffs:\n",
    "    click_train_pred = 1*(click_prob > cutoff)\n",
    "    accs.append(np.sum(click_train_pred == click_train)/len(click_train))\n",
    "    \n",
    "plt.figure(figsize=(6,4),dpi=100)\n",
    "plt.scatter(cutoffs,accs,s=10,c='k')\n",
    "plt.xlabel(\"Cutoff\",fontsize=10)\n",
    "plt.ylabel(\"Training Accuracy\",fontsize=10)\n",
    "plt.show() \n",
    "\n",
    "cutoff = 0.5\n",
    "click_train_pred = 1*(click_prob > cutoff)\n",
    "click_df = pd.DataFrame({'click_train':click_train,'click_predict':click_train_pred})\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "display(confusion_matrix(click_train, click_train_pred))\n",
    "print(precision_score(click_train, click_train_pred))\n",
    "print(recall_score(click_train, click_train_pred))\n",
    "print(np.sum(click_train_pred == click_train)/len(click_train))\n",
    "\"\"\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct a feature dataframe (180 in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = []\n",
    "for i in [1,2,3]:\n",
    "    for j in [1,2,3,4,5]:\n",
    "        for k in [0,1]:\n",
    "                for n in [1,2]:\n",
    "                    for m in [0,1]:\n",
    "                        if k == 0:\n",
    "                            feature.append([i,j,k,0,n,m])\n",
    "                            feature.append([i,j,k,1,n,m])\n",
    "                        else:\n",
    "                            feature.append([i,j,k,0,n,m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result of click probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(feature),columns=['Number of Vehicles','rank','Insured','NotInsured','Number of Drivers','Married'])\n",
    "click_prob = log_reg.predict_proba(df)[:,1]\n",
    "df['click_prob'] = click_prob\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(r'/Users/yushanyang/Documents/Study/summer camp/project/log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression for policy buying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X1_train,policy_train)\n",
    "\"\"\"\n",
    "The code below is for checking the accuracy,precision and recall:\n",
    "policy_prob = log_reg.predict_proba(X1_train)[:,1]\n",
    "cutoffs = np.arange(0,1.01,.01)\n",
    "accs = []\n",
    "for cutoff in cutoffs:\n",
    "    policy_train_pred = 1*(policy_prob > cutoff)\n",
    "    accs.append(np.sum(policy_train_pred == policy_train)/len(policy_train))\n",
    "    \n",
    "plt.figure(figsize=(6,4),dpi=100)\n",
    "plt.scatter(cutoffs,accs,s=10,c='k')\n",
    "plt.xlabel(\"Cutoff\",fontsize=10)\n",
    "plt.ylabel(\"Training Accuracy\",fontsize=10)\n",
    "plt.show() \n",
    "\n",
    "cutoff = 0.24\n",
    "policy_train_pred = 1*(policy_prob > cutoff)\n",
    "policy_df = pd.DataFrame({'polcy_train':policy_train,'policy_predict':policy_train_pred})\n",
    "display(confusion_matrix(policy_train, policy_train_pred))\n",
    "print(precision_score(policy_train, policy_train_pred))\n",
    "print(recall_score(policy_train, policy_train_pred))\n",
    "print(np.sum(policy_train_pred == policy_train)/len(policy_train))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result of policy buying probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(feature),columns=['Number of Vehicles','rank','Insured','NotInsured','Number of Drivers','Married'])\n",
    "policy_prob = log_reg.predict_proba(df)[:,1]\n",
    "df['policy_prob'] = policy_prob\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(r'/Users/yushanyang/Documents/Study/summer camp/project/log_policy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbors for clicking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(5,shuffle = True,random_state = 614)\n",
    "def get_acc(model,X,y):\n",
    "    pred = model.predict(X)\n",
    "    return np.sum(pred == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = X_train.loc[:,['Currently Insured','Number of Vehicles','Number of Drivers','Marital Status','rank']].copy()\n",
    "X1_train['Married'] = pd.get_dummies(X1_train.loc[:,'Marital Status'])['M']\n",
    "X1_train['Insured'] = pd.get_dummies(X1_train.loc[:,'Currently Insured'])['Y']\n",
    "X1_train['NotInsured'] = pd.get_dummies(X1_train.loc[:,'Currently Insured'])['N']\n",
    "X1_train = X1_train.loc[:,['Number of Vehicles','rank','Insured','NotInsured','Number of Drivers','Married']]\n",
    "X1_train_num = X1_train.to_numpy()\n",
    "click_train_num = click_train.to_numpy()\n",
    "policy_train_num = policy_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code below is for choosing the best number of neighbors:\n",
    "\n",
    "max_neighbors = 20\n",
    "accs = np.zeros((5,max_neighbors))\n",
    "j = 0\n",
    "for train_index, test_index in kfold.split(X1_train_num,click_train_num):\n",
    "    X1_train_train, X1_train_test = X1_train_num[train_index], X1_train_num[test_index]\n",
    "    click_train_train, click_train_test = click_train_num[train_index], click_train_num[test_index]\n",
    "    for i in range(1,max_neighbors+1):\n",
    "        knn = KNeighborsClassifier(i)       \n",
    "        knn.fit(X1_train_train, click_train_train.ravel())\n",
    "        accs[j,i-1] = get_acc(knn, X1_train_test, click_train_test.ravel())        \n",
    "    j=j+1 \n",
    "    \n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(6,4),dpi=100)\n",
    "plt.plot(range(1,max_neighbors+1), 100*np.mean(accs, axis=0))\n",
    "plt.xlabel(\"Features\", fontsize=10)\n",
    "plt.ylabel(\"Average CV Accuracy (%)\", fontsize=10)\n",
    "plt.show()  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(10)\n",
    "knn.fit(X1_train_num, click_train_num.ravel())\n",
    "\"\"\"\n",
    "The code below is for finding accuracy, precision and recall:\n",
    "\n",
    "click_prob = knn.predict_proba(X1_train_num)[:,1]\n",
    "cutoffs = np.arange(0,1.01,.01)\n",
    "accs = []\n",
    "for cutoff in cutoffs:\n",
    "    click_train_pred = 1*(click_prob > cutoff)\n",
    "    accs.append(np.sum(click_train_pred == click_train)/len(click_train))\n",
    "    \n",
    "plt.figure(figsize=(6,4),dpi=100)\n",
    "plt.scatter(cutoffs,accs,s=10,c='k')\n",
    "plt.xlabel(\"Cutoff\",fontsize=10)\n",
    "plt.ylabel(\"Training Accuracy\",fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "cutoff = 0.65\n",
    "click_train_pred = 1*(click_prob > cutoff)\n",
    "click_df = pd.DataFrame({'click_train':click_train,'click_predict':click_train_pred})\n",
    "display(confusion_matrix(click_train, click_train_pred))\n",
    "print(precision_score(click_train, click_train_pred))\n",
    "print(recall_score(click_train, click_train_pred))\n",
    "print(np.sum(click_train_pred == click_train)/len(click_train))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the clicking probability by k-nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(feature),columns=['Number of Vehicles','rank','Insured','NotInsured','Number of Drivers','Married'])\n",
    "click_prob = knn.predict_proba(feature)[:,1]\n",
    "df['click_prob'] = click_prob\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(r'/Users/yushanyang/Documents/Study/summer camp/project/knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code below is for choosing the best number of neighbors:\n",
    "\n",
    "max_neighbors = 20\n",
    "accs = np.zeros((5,max_neighbors))\n",
    "j = 0\n",
    "for train_index, test_index in kfold.split(X1_train_num,policy_train_num):\n",
    "    X1_train_train, X1_train_test = X1_train_num[train_index], X1_train_num[test_index]\n",
    "    policy_train_train, policy_train_test = policy_train_num[train_index], policy_train_num[test_index]\n",
    "    for i in range(1,max_neighbors+1):\n",
    "        knn = KNeighborsClassifier(i)       \n",
    "        knn.fit(X1_train_train, policy_train_train.ravel())\n",
    "        accs[j,i-1] = get_acc(knn, X1_train_test, policy_train_test.ravel())        \n",
    "    j=j+1 \n",
    "    \n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(6,4),dpi=100)\n",
    "plt.plot(range(1,max_neighbors+1), 100*np.mean(accs, axis=0))\n",
    "plt.xlabel(\"Features\", fontsize=10)\n",
    "plt.ylabel(\"Average CV Accuracy (%)\", fontsize=10)\n",
    "plt.show()  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(10)\n",
    "knn.fit(X1_train, policy_train.ravel())\n",
    "\"\"\"\n",
    "The code below is for finding accuracy, precision and recall:\n",
    "\n",
    "policy_prob = knn.predict_proba(X1_train)[:,1]\n",
    "cutoffs = np.arange(0,1.01,.01)\n",
    "accs = []\n",
    "for cutoff in cutoffs:\n",
    "    policy_train_pred = 1*(policy_prob > cutoff)\n",
    "    accs.append(np.sum(policy_train_pred == policy_train)/len(policy_train))\n",
    "    \n",
    "plt.figure(figsize=(6,4),dpi=100)\n",
    "plt.scatter(cutoffs,accs,s=10,c='k')\n",
    "plt.xlabel(\"Cutoff\",fontsize=10)\n",
    "plt.ylabel(\"Training Accuracy\",fontsize=10)\n",
    "plt.show()    \n",
    "\n",
    "cutoff = 0.4\n",
    "policy_train_pred = 1*(policy_prob > cutoff)\n",
    "policy_df = pd.DataFrame({'polcy_train':policy_train,'policy_predict':policy_train_pred})\n",
    "display(confusion_matrix(policy_train, policy_train_pred))\n",
    "print(precision_score(policy_train, policy_train_pred))\n",
    "print(recall_score(policy_train, policy_train_pred))\n",
    "print(np.sum(policy_train_pred == policy_train)/len(policy_train))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the policy buying probability by k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(feature),columns=['Number of Vehicles','rank','Insured','NotInsured','Number of Drivers','Married'])\n",
    "policy_prob = knn.predict_proba(feature)[:,1]\n",
    "df['policy_prob'] = policy_prob\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(r'/Users/yushanyang/Documents/Study/summer camp/project/knn_policy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
